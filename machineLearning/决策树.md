# 决策树
决策树的基本算法是贪心算法，它以自顶向下递归各个击破的方式构造决策树。

## 优缺点
分割方法
选择度量
ID3， C4.5 和最小GINI治标方法

### 优点
自学习 有监督

### 缺点
泛化能力弱 可能发现过拟合现象。(集成学习)
剪枝，随机森林

先剪枝，和后剪枝

## Bootstraping
自助法，又放回的抽样方法。

## 投票机制
一票否决  
少数服从多数  
阈值表决
贝叶斯投票  

## 混淆矩阵  

# 

## 概念
信息熵 决策树学习算法 bagging与随机森林
信息增益大的为 root
### 信息熵
将离散的随机变量x的概率分布为$P(X=xi)$
$H(X)=\sum{P(X)}log\frac{1}{P(X)}$

### 条件熵
条件熵表示在条件x下y的信息熵：公式如下：
$H(Y|X)=\sum{p(x)}H(Y|X=x)$
### 信息增益
信息增益=信息熵-条件熵  越大说明伤的变换也大，越有利于分类  

# kmeans 聚类算法
k-means 算法以k为参数， 把n个对象分成k个簇，是簇内就有较高的相似度，二簇间的相似度较低

随机选择k个点作为初始的聚类中心  
对于剩下的点，根据其余聚类中心的距离，将其归入最近的簇  
对每个簇，计算所有点的均值作为新的聚类中心  
重复2，3至聚类中心不在发生改变。  
